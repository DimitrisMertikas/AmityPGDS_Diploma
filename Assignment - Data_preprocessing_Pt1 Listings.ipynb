{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing Pt.1 - Listings in Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if kneed not available then we install so to find the optimal k for when we run kmeans later on\n",
    "#!conda install -c conda-forge kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df=pd.read_csv('listings.csv',low_memory=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we choose the features that we consider most relevant\n",
    "X=df[['id',\n",
    " 'host_id',\n",
    " 'host_response_rate',\n",
    " 'host_acceptance_rate',\n",
    " 'host_total_listings_count',\n",
    " 'host_has_profile_pic',\n",
    " 'host_identity_verified',\n",
    " 'street',\n",
    " 'neighbourhood',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'property_type',\n",
    " 'room_type',\n",
    " 'accommodates',\n",
    " 'bathrooms',\n",
    " 'bedrooms',\n",
    " 'beds',\n",
    " 'bed_type',\n",
    " 'price',\n",
    " 'minimum_nights',\n",
    " 'security_deposit',\n",
    " 'cleaning_fee',\n",
    " 'guests_included',\n",
    " 'extra_people',\n",
    " 'calendar_updated',\n",
    " 'has_availability',\n",
    " 'number_of_reviews',\n",
    " 'review_scores_rating',\n",
    " 'instant_bookable',\n",
    " 'is_business_travel_ready',\n",
    " 'cancellation_policy',\n",
    " 'require_guest_profile_picture',\n",
    " 'require_guest_phone_verification',\n",
    " 'calculated_host_listings_count',\n",
    " 'reviews_per_month',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove commas from numeric values\n",
    "pricecolumns=['price','security_deposit','cleaning_fee','host_response_rate','host_acceptance_rate','extra_people']\n",
    "for c in pricecolumns:\n",
    "    X[c]=X[c].replace({'\\$': ''}, regex=True)\n",
    "    X[c]=X[c].replace({'\\%': ''}, regex=True)\n",
    "    X[c]=X[c].replace({'\\\" \"': ''},regex=True)\n",
    "    X[c]=X[c].replace({',': ''}, regex=True)\n",
    "\n",
    "    \n",
    "\n",
    "#binary encode true false features\n",
    "binarycolumns =  ['host_identity_verified', 'host_has_profile_pic','instant_bookable','require_guest_profile_picture','has_availability',\n",
    "                  'require_guest_phone_verification','is_business_travel_ready']\n",
    "for c in binarycolumns:\n",
    "    X[c] = X[c].replace('f',0,regex=True)\n",
    "    X[c] = X[c].replace('t',1,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Null values with median in number of bedrooms, beds and bathrooms. For variables like cleaning fee, securiy deposit, review scores rating\n",
    "#reviews per month etc we cannot assume that there are missing values by negligence - the values might as well be zero as i.e new property without reviews,\n",
    "#or no requirement for security deposit or cleaning fee.\n",
    "\n",
    "X['bedrooms']=X['bedrooms'].fillna(X['bedrooms'].median())\n",
    "X['beds']=X['beds'].fillna(X['beds'].median())\n",
    "X['bathrooms']=X['bathrooms'].fillna(X['bathrooms'].median())\n",
    "X['cleaning_fee']=X['cleaning_fee'].fillna(0)\n",
    "X['security_deposit']=X['security_deposit'].fillna(0)\n",
    "X['review_scores_rating']=X['review_scores_rating'].fillna(0)\n",
    "X['reviews_per_month']=X['reviews_per_month'].fillna(0)\n",
    "X['host_total_listings_count']=X['host_total_listings_count'].fillna(0)\n",
    "X['host_has_profile_pic']=X['host_has_profile_pic'].fillna(0)\n",
    "X['host_identity_verified']=X['host_identity_verified'].fillna(0)\n",
    "\n",
    "#drop columns with a lot of nan value\n",
    "del X['review_scores_rating']\n",
    "del X['reviews_per_month']\n",
    "del X['neighbourhood']\n",
    "del X['host_response_rate']\n",
    "del X['host_acceptance_rate']\n",
    "del X['is_business_travel_ready']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check different categories\n",
    "print (X['property_type'].unique())\n",
    "print (X['room_type'].unique())\n",
    "print (X['bed_type'].unique())\n",
    "print (X['cancellation_policy'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see which type of properties are more common in Amsterdam. We wouldnt have much use for properties with very few listings\n",
    "property_occurence=X['property_type'].value_counts()\n",
    "property_occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we focus on the properties that are the most common - apartments and exclude rest types from our data\n",
    "value_counts = X['property_type'].value_counts()\n",
    "remove = value_counts[value_counts <= 14000].index\n",
    "X = X[~X.property_type.isin(remove)]\n",
    "X['property_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert objects to floats\n",
    "X[\"security_deposit\"] = X.security_deposit.astype(float)\n",
    "X[\"price\"] = X.price.fillna(0).astype(float)\n",
    "X[\"cleaning_fee\"] = X.cleaning_fee.astype(float)\n",
    "X[\"extra_people\"] = X.extra_people.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets have a look at some of the features which seem to have wide range of values\n",
    "print(X['price'].max())\n",
    "print(X['minimum_nights'].max())\n",
    "print(X['security_deposit'].max())\n",
    "print(X['accommodates'].max())\n",
    "print(X['extra_people'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "#pd.get_dummies(X, columns=[\"property_type\"]).head()\n",
    "X2 = pd.get_dummies(X, columns=['bed_type','room_type','cancellation_policy'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we remove outliers\n",
    "def remove_outlier(df,col_name):\n",
    "    q1=df[col_name].quantile(0.25)\n",
    "    q3=df[col_name].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    low=q1-1.5*iqr\n",
    "    high=q3+1.5*iqr\n",
    "    df_out=df.loc[(df[col_name]>low)&(df[col_name]<high)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outlier(X2,'minimum_nights')\n",
    "remove_outlier(X2,'price')\n",
    "remove_outlier(X2,'security_deposit')\n",
    "remove_outlier(X2,'beds')\n",
    "remove_outlier(X2,'extra_people')\n",
    "remove_outlier(X2,'accommodates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only numeric values to use for our Kmeans model\n",
    "numeric=X2.select_dtypes(exclude=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Kmeans algorithm for property classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(1,12)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k,n_init=12)\n",
    "    km = km.fit(numeric)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Kneed to find the best K value for our algorithm\n",
    "y=Sum_of_squared_distances\n",
    "\n",
    "x = range(1, len(y)+1)\n",
    "\n",
    "from kneed import KneeLocator\n",
    "kn = KneeLocator(x, y, curve='convex', direction='decreasing')\n",
    "print(kn.knee)\n",
    "plt.xlabel('number of clusters k')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.plot(x, y, 'bx-')\n",
    "plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#elbow method to determine cluster number\n",
    "SSE =[]\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters = i).fit(numeric)\n",
    "    kmeans.fit(numeric)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 10), SSE)\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE') #within cluster sum of squares\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaled_final_df = scaler.fit_transform(numeric)\n",
    "scaled_final_df = pd.DataFrame(scaled_final_df, columns=numeric.columns)\n",
    "\n",
    "scaled_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we remove variables that are not used as classiication parameters\n",
    "del scaled_final_df['id']\n",
    "del scaled_final_df['host_id']\n",
    "del scaled_final_df['latitude']\n",
    "del scaled_final_df['longitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we run Kmeans with k=3\n",
    "num_clusters=3\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "y_kmeans = kmeans.fit_predict(scaled_final_df)\n",
    "print(y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_kmeans.shape)\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2['Cluster']=y_kmeans\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import json \n",
    "\n",
    "!pip install geopy\n",
    "from geopy.geocoders import Nominatim \n",
    "!pip install geocoder\n",
    "\n",
    "import requests \n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "!pip install folium\n",
    "import folium\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use geolocator to find coordinates of Amsterdam and help us in visualizing the clusters on map\n",
    "address = 'Amsterdam, AMS'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"TO_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Amsterdam are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_airbnb = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "\n",
    "x = np.arange(num_clusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(num_clusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "markers_colors = []\n",
    "for lat, lon, cluster in zip(X2['latitude'], X2['longitude'], X2['Cluster']):\n",
    "    label = folium.Popup(' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=0.1,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=1).add_to(map_airbnb)\n",
    "\n",
    "map_airbnb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we name our clusters\n",
    "clus1 = X2.loc[X2.Cluster == 0] \n",
    "clus2 = X2.loc[X2.Cluster == 1] \n",
    "clus3 = X2.loc[X2.Cluster == 2] \n",
    "cluster_list = [clus1.values, clus2.values, clus3.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running Kmeans clustering second time in the cluster with the biggest density (Cluster 1) as the classes are very disproportionate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus1_numeric=clus1.select_dtypes(exclude=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(1,12)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k,n_init=12)\n",
    "    km = km.fit(clus1_numeric)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y=Sum_of_squared_distances\n",
    "\n",
    "x = range(1, len(y)+1)\n",
    "\n",
    "from kneed import KneeLocator\n",
    "kn = KneeLocator(x, y, curve='convex', direction='decreasing')\n",
    "print(kn.knee)\n",
    "plt.xlabel('number of clusters k')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.plot(x, y, 'bx-')\n",
    "plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=3\n",
    "kmeans = KMeans(n_clusters=clusters)\n",
    "y_kmeans = kmeans.fit_predict(clus1_numeric)\n",
    "print(y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus1['clustering']=y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_airbnb2 = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "\n",
    "x = np.arange(clusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(clusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "markers_colors = []\n",
    "for lat, lon, cluster in zip(clus1['latitude'], clus1['longitude'], clus1['clustering']):\n",
    "    label = folium.Popup(' clustering ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=0.1,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=1).add_to(map_airbnb2)\n",
    "\n",
    "map_airbnb2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Continued at Data Preprocessing Pt.2 - Calendar_Bookings*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
